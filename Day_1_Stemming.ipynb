{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwaRZUaUohVRICfQgmig/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanojpillai/GenerativeAI_100Days/blob/main/Day_1_Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgI8z1_IJSft"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is Stemming?**\n",
        "Stemming reduces words to their root form, or “stem,” by removing prefixes or suffixes. This process helps simplify data for models by reducing variations of words with similar meanings, like “eat,” “eating,” and “eaten,” all stemming to “eat.”\n",
        "\n",
        "For example, in a classification problem where we classify product reviews as positive or negative, we encounter various word forms that carry the same meaning. Stemming reduces these variations, which helps models focus on meaning rather than word forms.\n",
        "\n",
        "**Stemming Techniques**\n",
        "There are several stemming algorithms, each with its unique approach:\n",
        "\n",
        "**Porter Stemmer:** This algorithm is widely used and works well with many words, but sometimes produces inaccurate stems, especially with words like “history” or “congratulations,” where the stem loses meaning.\n",
        "\n",
        "**Regex Stemmer:** This approach uses custom regular expressions to remove specific suffixes or prefixes. For example, you can define a rule to strip “ing” or “s” from the ends of words. However, it has limitations, as it only matches specific patterns.\n",
        "\n",
        "**Snowball Stemmer:** An improvement over the Porter Stemmer, the Snowball Stemmer provides better accuracy with many words and supports multiple languages. For example, it accurately stems words like “fairly” and “sportingly” to “fair” and “sport.”\n",
        "\n",
        "**Limitations of Stemming**\n",
        "Stemming can sometimes distort the meaning of words, making it less suitable for nuanced applications like chatbots or complex text analysis. For instance, words like “goes” might not stem correctly, resulting in errors."
      ],
      "metadata": {
        "id": "bjywcQgqJaXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "Q_3bDla-JtGq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemming = PorterStemmer()"
      ],
      "metadata": {
        "id": "VWgdgIHXJxwl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in ['going','goes','go','intelligent','intelligence','intelligently','feet','foot','cars','car']:\n",
        "    print(stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sve7U5_LJ8D7",
        "outputId": "2a8a8ea4-c049-445e-e6ac-51c7506347e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go\n",
            "goe\n",
            "go\n",
            "intellig\n",
            "intellig\n",
            "intellig\n",
            "feet\n",
            "foot\n",
            "car\n",
            "car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem('happiness')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PlNiDkWtJ-GP",
        "outputId": "815a63b9-7462-4ca7-a366-f4eb6b0a288f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "metadata": {
        "id": "jVKmFH-eKUEm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
      ],
      "metadata": {
        "id": "gO3MpKOjKmTC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_stemmer.stem('eating')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4FqurLyXKyx-",
        "outputId": "b4d01ecf-5e86-464a-8834-ad73aee54c86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "El7ZkOcsK3VL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}